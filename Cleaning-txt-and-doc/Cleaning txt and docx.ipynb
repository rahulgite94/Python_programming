{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file, remove punctuation and stop words​<br>\n",
    "\n",
    "Produce a single .dat file containing the name of each file in quotes, a colon, then a list of words separated by commas​. The list of words per file should be unique for that file. Do not include URLs or phone numbers. Words should be made lowercase. <br>\n",
    "\n",
    "Example output:<br>\n",
    "\n",
    "\"File 1.txt\" : word1, word2, word3, word7​<br>\n",
    "\"name of file.docx\" : word8, word2, word1, word10​<br>\n",
    "\"another file.doc\" : word1, word12, word6​<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import os\n",
    "import fnmatch\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "URL Regular Expression reference from stackoverflow <br>\n",
    "https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regxUrl=\"https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|http?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phone number Regular Expression reference from regexlib <br>\n",
    "http://regexlib.com/REDetails.aspx?regexp_id=283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regxPhoneNumber=\"\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the list of punctualtion marks and adding some more to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation=list(string.punctuation)\n",
    "punctuation.append('--')\n",
    "punctuation.append('“')\n",
    "punctuation.append('”')\n",
    "punctuation.append('’')\n",
    "punctuation.append('‘')\n",
    "punctuation.append('-')\n",
    "punctuation.append('—')\n",
    "punctuation.append('``')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file= open(\"AssignmentFile.dat\",\"w+\") # output file\n",
    "en_stops = set(stopwords.words('english')) # Stope Words taken\n",
    "foldr='week_10_txt_and_docx/' # folder in which the files are kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file_name in os.listdir(foldr):\n",
    "    if fnmatch.fnmatch(file_name, '*.txt'):# Matching the txt file\n",
    "        file.write('\"'+file_name+'\" : ')# writing file name to output file\n",
    "        with open(foldr+file_name,'r', encoding=\"utf-8-sig\") as fil: # Opening the file\n",
    "            fileContent=fil.read().lower() # set to lower case\n",
    "            fileContent=(\" \".join(sorted(set(fileContent.split()), key=fileContent.split().index))) # removing repetative strings\n",
    "            urlRemoved=re.sub(regxUrl, \"\", fileContent) # removing URL using reqx\n",
    "            phoneNumberRemoved=re.sub(regxPhoneNumber, \"\", urlRemoved) # removing Phone number using regx\n",
    "            sent_tokenize_list = sent_tokenize(phoneNumberRemoved) # forming sentance\n",
    "            for this_sent in sent_tokenize_list: \n",
    "                word_tokens=word_tokenize(this_sent) # forming words\n",
    "                for w in word_tokens:\n",
    "                    if w not in en_stops:  # excluding stop words\n",
    "                        if w not in list(punctuation): #excluding punctuation marks\n",
    "                            file.write(w+',') # writing the filtered words to file\n",
    "        file.write('\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file_name in os.listdir(foldr):\n",
    "    if fnmatch.fnmatch(file_name, '*.docx'):# Matching the docx file\n",
    "        file.write('\"'+file_name+'\" : ')# writing file name to output file\n",
    "        document = Document(foldr+file_name)\n",
    "        indx=0\n",
    "        docFileContent=[]\n",
    "        fileContent1=''\n",
    "        for para in document.paragraphs:\n",
    "            if (len(para.text)>0):\n",
    "                indx+=1\n",
    "                docFileContent.append(para.text.lower()) # storing each text to list\n",
    "        fileContent1=fileContent1.join(docFileContent) # converting list to string\n",
    "        fileContent=(\" \".join(sorted(set(fileContent1.split()), key=fileContent1.split().index)))# removing repetative strings\n",
    "        urlRemoved=re.sub(regxUrl, \"\", fileContent) # removing URL using reqx\n",
    "        phoneNumberRemoved=re.sub(regxPhoneNumber, \"\", urlRemoved)  # removing Phone number using reqx\n",
    "        sent_tokenize_list = sent_tokenize(phoneNumberRemoved)# forming sentance\n",
    "        for this_sent in sent_tokenize_list:\n",
    "            word_tokens=word_tokenize(this_sent)# forming words\n",
    "            for w in word_tokens:\n",
    "                if w not in en_stops:  # excluding stop words\n",
    "                    if w not in list(punctuation):#excluding punctuation marks\n",
    "                        file.write(w+',')# writing the filtered words to file\n",
    "        file.write('\\r\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close() # closing the file after write"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
